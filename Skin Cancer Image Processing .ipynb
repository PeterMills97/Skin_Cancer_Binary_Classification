{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82ed2881",
   "metadata": {},
   "source": [
    "# Image Processing "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c900fe3",
   "metadata": {},
   "source": [
    "The goal of this note book is to process the Kaggle dataset so that it is ready for use training some models using VGG16. Along with the basic processing, I have also done a little data augmentation, using numpy and basic linear algebra. \n",
    "\n",
    "One significant decison I made during this was to omit any test set and only use a train and dev set, this is motivated by the limited size of the dataset. Because of the small size of the dataset, it was more benificial to put more data into development and simply live without a very accurate final evaluation of performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41635ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc76e881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 288 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "Total_data=tf.keras.utils.image_dataset_from_directory('Skin_Data/',batch_size=None\n",
    "                                                       ,labels=\"inferred\",label_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "196f8ff2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'plt.figure()\\nfor image, labels in Total_data.take(1):\\n    print(np.shape(image))\\n    print(labels)\\n    plt.imshow(image/255)\\n    \\nplt.show()'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''plt.figure()\n",
    "for image, labels in Total_data.take(1):\n",
    "    print(np.shape(image))\n",
    "    print(labels)\n",
    "    plt.imshow(image/255)\n",
    "    \n",
    "plt.show()'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7cade5",
   "metadata": {},
   "source": [
    "We see image_dataset_from_directory has labeled 70% of the data 1, but the positive class only has 30% so we will need to flip these labels later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f89c9e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0.7083333, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "items=Total_data.cardinality().numpy()\n",
    "total_labels=0\n",
    "for images, labels in Total_data.take(items):\n",
    "    total_labels+=labels[0]\n",
    "print(total_labels/items)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2cf1191",
   "metadata": {},
   "source": [
    "## Train test split: Convert to Numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872c7b55",
   "metadata": {},
   "source": [
    "By first converting our tensors to numpy arrays, we can use sklearn's train test split, which allows for stratified splitting, which is necessary because of the small size of the dataset. As far as I know, this is not possible using tensorflows utensils."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d6824ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(288, 256, 256, 3) (288, 1)\n"
     ]
    }
   ],
   "source": [
    "image_list=[]\n",
    "label_list=[]\n",
    "for image, label in Total_data.take(Total_data.cardinality().numpy()):\n",
    "    image_list.append(image.numpy())\n",
    "    label_list.append(label.numpy())\n",
    "X=np.array(image_list)\n",
    "y=np.array(label_list)\n",
    "y=[1]-y\n",
    "print(np.shape(X),np.shape(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa118b7c",
   "metadata": {},
   "source": [
    "Because of the limited data I'm using, it seems wise to dispense with a separate test set. this will mean that we will have to do without a very accurate measure of the models performance but this is fime for our purposes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8dccdf0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 60-40 split reflects limited size of dataset\n",
    "X_train, X_dev, y_train, y_dev = train_test_split(X, y, test_size=0.4,stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29098152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.29069767441860467 0.29310344827586204\n"
     ]
    }
   ],
   "source": [
    "#check the stratification\n",
    "print(y_train.mean(),y_dev.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1283a354",
   "metadata": {},
   "source": [
    "## Augment our training data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb3ef1a",
   "metadata": {},
   "source": [
    "Is it necessary to augment our data when using a pretrained model as a base? Perhaps not. The base model has already learnt to recognise transformed images so this may not be so useful. I decided to give augmenting my data a try anyway as it is a relatively small investment becuase of the size of the dataset. Even considering this, it will slow down training noticably (we are effectively using a training set that is 8 times larger) \n",
    "\n",
    "I'm aware that there are some pytorch tools that can be used for this task but I opted to simply use numpy and some linear algebra, making use of numpy's vectorisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4bb0ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a matrix to use to apply reflections \n",
    "def reflection_array(image_number):\n",
    "    I_array=np.identity(256)\n",
    "    reflect_array=np.zeros((image_number,256,256,3))\n",
    "    for n in range(image_number):\n",
    "        for j in range(3):\n",
    "            for i in range(256):\n",
    "                reflect_array[n,i,:,j]=I_array[255-i,:]\n",
    "    return reflect_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7df4bc51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# applies an x axis reflection to a copy of the data and concatenates it with the original \n",
    "def x_reflection(image_set,label_set):\n",
    "    image_number=np.shape(image_set)[0]\n",
    "    new_images=np.zeros((256,256,3))\n",
    "    new_images=np.matmul(np.moveaxis(image_set[:,:,:,:],-1,0),np.moveaxis(reflection_array(image_number),-1,0))\n",
    "    new_images=np.moveaxis(new_images,0,-1)\n",
    "    \n",
    "    total_images=np.concatenate((image_set,new_images),axis=0)  \n",
    "    total_labels=np.concatenate((label_set,label_set),axis=0) #concatenate preserves row order\n",
    "    \n",
    "    return total_images, total_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d531cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# applies an y axis reflection to a copy of the data and concatenates it with the original\n",
    "def y_reflection(image_set,label_set):\n",
    "    image_number=np.shape(image_set)[0]\n",
    "    new_images=np.zeros((256,256,3))\n",
    "    new_images=np.matmul(np.moveaxis(reflection_array(image_number),-1,0),np.moveaxis(image_set[:,:,:,:],-1,0))\n",
    "    new_images=np.moveaxis(new_images,0,-1)\n",
    "    \n",
    "    total_images=np.concatenate((image_set,new_images),axis=0)  \n",
    "    total_labels=np.concatenate((label_set,label_set),axis=0) #concatenate preserves row order\n",
    "    \n",
    "    return total_images, total_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21c47ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flips x and y cooridinates in a copy of the data and concatenates it with the original \n",
    "#for those interested in the linear algera, this is equivalent to a reflection in the line y=x\n",
    "def x_y_flip(image_set,label_set):\n",
    "    new_images=np.moveaxis(image_set,1,2)\n",
    "    \n",
    "    total_images=np.concatenate((image_set,new_images),axis=0)  \n",
    "    total_labels=np.concatenate((label_set,label_set),axis=0)\n",
    "    \n",
    "    return total_images, total_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9fa550d",
   "metadata": {},
   "source": [
    "Using the three reflection functions we have created, we can generate all possible linear transformations of our square image onto itself. I decided not to apply any non-linear transformations or change the colour of any images as I am unsure if this is justified for this classification task.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cfe33316",
   "metadata": {},
   "outputs": [],
   "source": [
    "Augmented_X, Augmented_y=x_reflection(X_train,y_train)\n",
    "Augmented_X, Augmented_y=y_reflection(Augmented_X, Augmented_y)\n",
    "Augmented_X, Augmented_y=x_y_flip(Augmented_X, Augmented_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6b09500a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fig, axs=plt.subplots(2,4)\\nfor n in range(8):\\n    axs[n//4,n%4].imshow(Augmented_X[20+(n*172),:,:,:]/255.0)\\n    axs[n//4,n%4].axis(\"off\") \\n    axs[n//4,n%4].set_title(f\\'{Augmented_y[20+(n*172)]}\\')'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''fig, axs=plt.subplots(2,4)\n",
    "for n in range(8):\n",
    "    axs[n//4,n%4].imshow(Augmented_X[20+(n*172),:,:,:]/255.0)\n",
    "    axs[n//4,n%4].axis(\"off\") \n",
    "    axs[n//4,n%4].set_title(f'{Augmented_y[20+(n*172)]}')'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7496cee",
   "metadata": {},
   "source": [
    "Final step: run the keras vgg16 preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c130bfac",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vvg16=tf.keras.applications.vgg16.preprocess_input(Augmented_X)\n",
    "X_dev_vvg16=tf.keras.applications.vgg16.preprocess_input(X_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeabba8e",
   "metadata": {},
   "source": [
    "## Save data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5aade00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('Skin_cancer_X_train', X_train_vvg16)\n",
    "np.save('Skin_cancer_y_train', Augmented_y)\n",
    "\n",
    "np.save('Skin_cancer_X_dev', X_dev_vvg16)\n",
    "np.save('Skin_cancer_y_dev', y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9469f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
